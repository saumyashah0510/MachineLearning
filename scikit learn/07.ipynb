{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "940df0c8",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "\n",
    "ðŸ”¹ The Problem\n",
    "\n",
    "If you train and test on the same dataset, your model might look perfect, but itâ€™s actually just memorizing (overfitting).\n",
    "So we split data into train and test. But one single split might be misleading (maybe the test set is too easy/hard).\n",
    "\n",
    "ðŸ”¹ The Solution â†’ Cross-Validation\n",
    "\n",
    "Cross-validation avoids this by splitting the dataset into multiple folds (subsets) and training/testing the model on different combinations.\n",
    "\n",
    "ðŸŸ¢ Example: k-Fold Cross Validation\n",
    "\n",
    "Split the data into k equal parts (folds).\n",
    "\n",
    "For each round:\n",
    "\n",
    "Use k-1 folds for training\n",
    "\n",
    "Use 1 fold for testing\n",
    "\n",
    "Repeat k times (so each fold is used once as a test set).\n",
    "\n",
    "Take the average score across all k runs.\n",
    "\n",
    "ðŸ‘‰ Example with k=5:\n",
    "\n",
    "Round 1: Train on folds 2â€“5, test on fold 1\n",
    "\n",
    "Round 2: Train on folds 1,3â€“5, test on fold 2\n",
    "\n",
    "â€¦\n",
    "\n",
    "Round 5: Train on folds 1â€“4, test on fold 5\n",
    "\n",
    "ðŸŸ¢ Benefits\n",
    "\n",
    "More reliable estimate of performance (not dependent on one split).\n",
    "\n",
    "Uses the entire dataset for both training and testing (different rounds).\n",
    "\n",
    "Helps detect overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f2fbcc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
